{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Arvore de decisão.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlineBarrucci26/Arvore_decisao/blob/main/Arvore_de_decis%C3%A3o.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR-3FxrUIoRQ"
      },
      "source": [
        "Arvoré de Regressão\n",
        "O algoritmo para modelos de árvore de decisão funciona particionando repetidamente os dados em vários subespaços, de forma que os resultados em cada subespaço final sejam o mais homogêneos possível. Essa abordagem é tecnicamente chamada de particionamento recursivo. O resultado obtido consiste em um conjunto de regras usadas para prever a variável de resultado, continua para árvores de regressão e categórica para árvores de classificação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PONhsr7IoRb"
      },
      "source": [
        "#importando as bicliotecas que serão usadas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUpHXhlDIoRc"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import tree\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8b8lppjIoRd"
      },
      "source": [
        "# carregamos o dataset \n",
        "iris = load_iris()\n",
        "# separamos as features e os targets\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL2MhoxJIoRe"
      },
      "source": [
        "# Definimos a árvore de decisão com o critério de entropia\n",
        "clf = tree.DecisionTreeClassifier(criterion=\"entropy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq8Q3JitIoRf"
      },
      "source": [
        "Esse algoritmo é baseado na ideia de entropia. A entropia de um dataset é uma métrica da sua incerteza ou impureza, ou seja, representa a aleatoriedade em seus valores. O seu valor é zero quando não há aleatoriedade (todos os elementos do dataset tem a mesma classificação) e aumenta conforme o dataset fica mais impuro."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BdkA-YDIoRg"
      },
      "source": [
        "# construimos a árvore a partir do dataset\n",
        "irisTree = clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DGm64ECIoRg",
        "outputId": "40d93748-f980-4076-c51e-dec05c98a8c3"
      },
      "source": [
        "irisTree.predict([[2., 2., 2., 2.]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDEqyEHBIoRi"
      },
      "source": [
        "Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWVS8-rSIoRi",
        "outputId": "b8acca7d-a03b-4a6b-9f73-2dd1501eb2cd"
      },
      "source": [
        "allScores = cross_val_score(clf, X, y , cv=10)\n",
        "# cross_val_score retorna array com as 10 validações\n",
        "allScores.mean() # tomamos a média do score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9533333333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXXymAXTIoRj"
      },
      "source": [
        "Arvore de Classificação\n",
        "Uma árvore de classificação é muito semelhante a uma árvore de regressão, exceto que é usada para prever uma resposta qualitativa em vez de quantitativa.\n",
        "Para uma árvore de classificação, prevemos que cada observação pertence à classe de observações de treinamento mais comum na região à qual pertence. Portanto quando interpretamos os resultados de uma árvore de classificação, muitas vezes estaremos interessados não só na previsão de classe correspondente a região de nó terminal, mas também nas proporções de classe entre as observações de treinamento que pertencem aquela região."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-7n0mruIoRk"
      },
      "source": [
        "Já o CART pode ser utilizado pela classe DecisionTreeRegressor.\n",
        "CART — Classification and Regression Tree (Árvore de Classificação e Regressão)\n",
        "Esse algoritmo é similar ao ID3, porém utiliza probabilidade para medir a impureza de um dataset, ao invés da entropia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sba89oRPIoRk"
      },
      "source": [
        "Vamos aplicar esse algoritmo no dataset Boston Housing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UkKU2hZIoRl"
      },
      "source": [
        "# imports básicos\n",
        "from sklearn import tree\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m1b1RaIIoRl"
      },
      "source": [
        "# carregamos o dataset \n",
        "boston = load_boston()\n",
        "# separamos as features e os targets\n",
        "X = boston.data\n",
        "y = boston.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq0HR6UZIoRl"
      },
      "source": [
        "Definimos a árvore de decisão com CART"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9i9b5aOIoRm"
      },
      "source": [
        "reg = tree.DecisionTreeRegressor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMKwftwLIoRm"
      },
      "source": [
        "# construimos a árvore a partir do dataset\n",
        "bostonTree = reg.fit(X[:-50], y[:-50])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-x92n4qIoRn"
      },
      "source": [
        "Desse modo podemos fazer predições no dataset com a função predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RDjCSHhIoRn",
        "outputId": "b229f954-d88b-4aa3-895a-84ce32710a94"
      },
      "source": [
        "bostonTree.predict(X[-50:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([13.2, 15.1, 13.4, 13.4, 14.1, 15.6, 22.7, 22.7, 22.7, 20.8, 13.2,\n",
              "       13.2, 10.2, 10.9, 14.1, 22.7, 19.9, 29.6, 15.1, 17.2, 14.1, 16.3,\n",
              "       14.1, 21.7, 22.7, 22.8, 29.6, 18.2, 24.7, 20.8, 17.4, 22.7, 16.2,\n",
              "       15.7, 15.7, 17.4, 19.2, 16.1, 24.7, 19.4, 19.5, 17.4, 19.2, 19.5,\n",
              "       19.2, 30.8, 22.2, 23.6, 28.4, 22.2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF-eMGGqIoRo",
        "outputId": "28b832c7-65da-4f34-c94d-fe2964d86449"
      },
      "source": [
        "# score usando os últimos 50 valores como dados de teste\n",
        "# a métrica usada para calcular o score é o R2\n",
        "bostonTree.score(X[-50:], y[-50:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.04960530989402501"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sgIssBsIoRo"
      },
      "source": [
        "Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gseKYgO8IoRp",
        "outputId": "0781ea0c-f66b-43eb-d0ee-1f63fc31ee20"
      },
      "source": [
        "# scores das validações cruzadas\n",
        "allScores = cross_val_score(reg, X, y, cv=10)\n",
        "print(allScores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.54037717  0.61706033 -1.61609132  0.54024689  0.78342992  0.39773123\n",
            "  0.21473508  0.37556686 -2.04424203  0.06430082]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a9DGVuQIoRp",
        "outputId": "b800cd88-b146-4698-c2ba-1de0652614cc"
      },
      "source": [
        "# média dos scores\n",
        "allScores.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.012688503824221231"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}